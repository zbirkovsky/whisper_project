[application]
name = "CloudCall Transcription"
version = "1.0.0"
organization = "CloudCall"

[paths]
# Application data directory (default: ~/.cloudcall)
# app_dir = "C:\\Users\\YourUser\\.cloudcall"
# Audio recordings directory (default: ~/.cloudcall/recordings)
# recordings_dir = "C:\\Users\\YourUser\\.cloudcall\\recordings"

[transcription]
# Whisper model: tiny, base, small, medium, large-v2, large-v3, large-v3-turbo
whisper_model = "large-v3"  # Default model for auto-detection
compute_type = "float32"  # float32 for best CPU quality (int8 degrades quality)
batch_size = 8  # REDUCED from 16 for better quality on CPU
device = "cpu"  # CPU mode (RTX 5090 not yet supported by PyTorch - will be available in future)
language = "en"  # ENGLISH ONLY for bulletproof accuracy (en=English, cs=Czech, auto=detect)

# Language-specific models for optimal quality
model_czech = "whisper-large-v3-czech-cv13-ct2"  # 7.89% WER - 27% better for Czech
model_english = "large-v3-turbo"  # 8x faster for English
model_fallback = "large-v3"  # Used when language unknown or model not available

[audio]
sample_rate = 48000  # Recording sample rate (mic native rate)
whisper_sample_rate = 16000  # Downsample to 16kHz for Whisper (native rate)
channels = 2  # Record in stereo, convert to mono after
chunk_size = 2048  # Larger chunk size for better recording performance
audio_format = "int16"

[diarization]
enabled = true
min_speakers = 1
max_speakers = 10
# HuggingFace authentication token for Pyannote models
# Get token from: https://huggingface.co/settings/tokens
# Required for speaker diarization
hf_token = ""

[ui]
theme = "auto"  # auto, light, dark
window_width = 1000
window_height = 700

[logging]
log_level = "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
max_log_size_mb = 10
backup_count = 5
