[application]
name = "CloudCall Transcription"
version = "1.0.0"
organization = "CloudCall"

[paths]
# Application data directory (default: ~/.cloudcall)
# app_dir = "C:\\Users\\YourUser\\.cloudcall"
# Audio recordings directory (default: ~/.cloudcall/recordings)
# recordings_dir = "C:\\Users\\YourUser\\.cloudcall\\recordings"

[transcription]
# Whisper model: tiny, base, small, medium, large-v2, large-v3, large-v3-turbo
whisper_model = "large-v3"  # Default model for auto-detection
compute_type = "float16"  # float16 for GPU, int8 for CPU
batch_size = 16
device = "cuda"  # GPU acceleration enabled with RTX 4090
language = "auto"  # auto-detect, cs (Czech), en (English)

# Language-specific models for optimal quality
model_czech = "whisper-large-v3-czech-cv13-ct2"  # 7.89% WER - 27% better for Czech
model_english = "large-v3-turbo"  # 8x faster for English
model_fallback = "large-v3"  # Used when language unknown or model not available

[audio]
sample_rate = 48000
channels = 2
chunk_size = 512
audio_format = "int16"

[diarization]
enabled = true
min_speakers = 1
max_speakers = 10
# HuggingFace authentication token for Pyannote models
# Get token from: https://huggingface.co/settings/tokens
# Required for speaker diarization
hf_token = ""

[ui]
theme = "auto"  # auto, light, dark
window_width = 1000
window_height = 700

[logging]
log_level = "INFO"  # DEBUG, INFO, WARNING, ERROR, CRITICAL
max_log_size_mb = 10
backup_count = 5
